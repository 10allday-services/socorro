import socorro.lib.ConfigurationManager as cm
import datetime
import stat

#---------------------------------------------------------------------------
# Relational Database Section

databaseHost = cm.Option()
databaseHost.doc = 'the hostname of the database servers'
databaseHost.default = 'localhost'

databasePort = cm.Option()
databasePort.doc = 'the port of the database on the host'
databasePort.default = 5432

databaseName = cm.Option()
databaseName.doc = 'the name of the database within the server'
databaseName.default = ''

databaseUserName = cm.Option()
databaseUserName.doc = 'the user name for the database servers'
databaseUserName.default = ''

databasePassword = cm.Option()
databasePassword.doc = 'the password for the database user'
databasePassword.default = ''

#---------------------------------------------------------------------------
# Crash storage system

crashStorageClass = cm.Option()
crashStorageClass.doc = 'the name of the class used to store crashes (CrashStorageSystemForHBase or CrashStorageSystemForNFS)'
crashStorageClass.default = 'CrashStorageSystemForHBase'

jsonFileSuffix = cm.Option()
jsonFileSuffix.doc = 'the suffix used to identify a json file'
jsonFileSuffix.default = '.json'

dumpFileSuffix = cm.Option()
dumpFileSuffix.doc = 'the suffix used to identify a dump file'
dumpFileSuffix.default = '.dump'

#---------------------------------------------------------------------------
# HBase storage system
if crashStorageClass.default == 'CrashStorageSystemForHBase':
  hbaseHost = cm.Option()
  hbaseHost.doc = 'Hostname for hbase hadoop cluster. May be a VIP or load balancer'
  hbaseHost.default = 'localhost'

  hbasePort = cm.Option()
  hbasePort.doc = 'hbase port number'
  hbasePort.default = 9090

  hbaseTimeout = cm.Option()
  hbaseTimeout.doc = 'timeout in milliseconds for an HBase connection'
  hbaseTimeout.default = 5000

#---------------------------------------------------------------------------
# NFS storage system
if crashStorageClass.default == 'CrashStorageSystemForNFS':
  storageRoot = cm.Option()
  storageRoot.doc = 'the root of the file system where dumps are found'
  storageRoot.default = '/tmp/socorro/toBeProcessed/'

  deferredStorageRoot = cm.Option()
  deferredStorageRoot.doc = 'the root of the file system where dumps are found'
  deferredStorageRoot.default = '/tmp/socorro/toBeDeferred/'

  processedDumpStoragePath = cm.Option()
  processedDumpStoragePath.doc = 'the path of the file system where processed dumps are stored'
  processedDumpStoragePath.default = '/tmp/socorro/processedDumpStorage/'

  dumpDirPrefix = cm.Option()
  dumpDirPrefix.doc = 'dump directory names begin with this prefix'
  dumpDirPrefix.default = 'bp_'

  dumpDirCount = cm.Option()
  dumpDirCount.doc = 'the number of dumps to be stored in a single directory'
  dumpDirCount.default = 1024

  dumpGID = cm.Option()
  dumpGID.doc="the group ID on minidumps so that they can be deleted by other users (optional)"
  dumpGID.default = None

  dumpPermissions = cm.Option()
  dumpPermissions.doc = 'when saving dumps, the pemission flags to be used'
  dumpPermissions.default = '%d'%(stat.S_IRGRP | stat.S_IWGRP | stat.S_IRUSR | stat.S_IWUSR)

  dirPermissions = cm.Option()
  dirPermissions.doc = 'when saving dumps, the permission flags to be used on directories'
  dirPermissions.default = '%d'%(stat.S_IRGRP | stat.S_IXGRP | stat.S_IWGRP | stat.S_IRUSR | stat.S_IXUSR | stat.S_IWUSR)

#---------------------------------------------------------------------------
# misc

processorCheckInTime = cm.Option()
processorCheckInTime.doc = 'the time after which a processor is considered dead (hh:mm:ss)'
processorCheckInTime.default = "00:05:00"
processorCheckInTime.fromStringConverter = lambda x: str(cm.timeDeltaConverter(x))

startWindow = cm.Option()
startWindow.doc = 'The start of the single aggregation window (YYYY-MM-DD [hh:mm:ss])'
startWindow.fromStringConverter = cm.dateTimeConverter

deltaWindow = cm.Option()
deltaWindow.doc = 'The length of the single aggregation window  ([dd:]hh:mm:ss)'
deltaWindow.fromStringConverter = cm.timeDeltaConverter

defaultDeltaWindow = cm.Option()
defaultDeltaWindow.doc = 'The length of the single aggregation window  ([dd:]hh:mm:ss)'
defaultDeltaWindow.fromStringConverter = cm.timeDeltaConverter

# override this default for your particular cron task
defaultDeltaWindow.default = '00:12:00'

endWindow = cm.Option()
endWindow.doc = 'The end of the single aggregation window (YYYY-MM-DD [hh:mm:ss])'
endWindow.fromStringConverter = cm.dateTimeConverter

startDate = cm.Option()
startDate.doc = 'The start of the overall/outer aggregation window (YYYY-MM-DD [hh:mm])'
startDate.fromStringConverter = cm.dateTimeConverter

deltaDate = cm.Option()
deltaDate.doc = 'The length of the overall/outer aggregation window  ([dd:]hh:mm:ss)'
deltaDate.fromStringConverter = cm.timeDeltaConverter

initialDeltaDate = cm.Option()
initialDeltaDate.doc = 'The length of the overall/outer aggregation window  ([dd:]hh:mm:ss)'
initialDeltaDate.fromStringConverter = cm.timeDeltaConverter

# override this default for your particular cron task
initialDeltaDate.default = '4:00:00:00'

minutesPerSlot = cm.Option()
minutesPerSlot.doc = 'how many minutes per leaf directory in the date storage branch'
minutesPerSlot.default = 1

endDate = cm.Option()
endDate.doc = 'The end of the overall/outer aggregation window (YYYY-MM-DD [hh:mm:ss])'
endDate.fromStringConverter = cm.dateTimeConverter

debug = cm.Option()
debug.doc = 'do debug output and routines'
debug.default = False
debug.singleCharacter = 'D'
debug.fromStringConverter = cm.booleanConverter

